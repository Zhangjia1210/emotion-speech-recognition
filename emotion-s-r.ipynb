{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Feature Extraction for Emotion Recognition\n",
    "\n",
    "This script is designed to extract audio features from a dataset of emotional speech. The dataset is organized into multiple folders, each representing a different speaker, with audio files categorized by emotions. Here's an overview of the process:\n",
    "\n",
    "1. Set Up the Directory: \n",
    "   - The base directory containing the dataset is defined.\n",
    "   - The dataset is expected to have a specific structure: each speaker has a dedicated folder containing subfolders for different emotions.\n",
    "\n",
    "2. Initialize Data Storage:\n",
    "   - An empty list, data, is created to store the features and labels extracted from the audio files.\n",
    "\n",
    "3. Iterate Through Speaker Folders:\n",
    "   - The script iterates over each speaker's folder within the base directory.\n",
    "   - For each speaker, it reads a text file that contains mappings of audio filenames to their corresponding emotional labels.\n",
    "\n",
    "4. Extract Audio Features:\n",
    "   - The script processes each audio file in the emotion folders.\n",
    "   - Using the librosa library, it extracts various features from the audio files, including Mel-frequency cepstral coefficients (MFCCs), root mean square energy (RMSE), and delta MFCCs.\n",
    "   - These features are stacked and averaged to create a single feature vector for each audio file.\n",
    "\n",
    "5. Label Assignment:\n",
    "   - Each audio file is labeled with the correct emotion based on the mapping obtained from the text file.\n",
    "\n",
    "6. Data Compilation:\n",
    "   - The extracted features and corresponding emotion labels are compiled into a Pandas DataFrame.\n",
    "   - This DataFrame, df, is ready for further processing and can be used for training machine learning models for emotion recognition.\n",
    "\n",
    "### Exception Handling\n",
    "\n",
    "- The script includes error handling to manage issues like missing files or extraction errors, ensuring robustness in data processing.\n",
    "\n",
    "### Output\n",
    "\n",
    "- The final output is a DataFrame where each row represents an audio file, with columns for extracted features and the associated emotion label.\n",
    "\n",
    "This script lays the foundation for building and training a model to recognize emotions from speech, leveraging audio signal processing and machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = 'C:\\Users\\张佳\\source\\repos\\emotion-speech-recognition\\Emotion Speech Dataset'\n",
    "\n",
    "# Initialize a list to store data\n",
    "data = []\n",
    "\n",
    "# Iterate over each speaker's folder\n",
    "for speaker_folder in os.listdir(base_dir):\n",
    "    speaker_path = os.path.join(base_dir, speaker_folder)\n",
    "\n",
    "    # Read the corresponding text file for the speaker\n",
    "    mapping_file = os.path.join(speaker_path, f\"{speaker_folder}.txt\")\n",
    "    mapping = {}\n",
    "    with open(mapping_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                # Append \".wav\" to the filename from the text file for matching\n",
    "                mapping[parts[0].strip() + \".wav\"] = parts[2].strip()\n",
    "            else:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "\n",
    "    # Process each audio file in the emotion folders\n",
    "    for emotion_folder in os.listdir(speaker_path):\n",
    "        emotion_path = os.path.join(speaker_path, emotion_folder)\n",
    "        if os.path.isdir(emotion_path):\n",
    "            for audio_file in os.listdir(emotion_path):\n",
    "                file_path = os.path.join(emotion_path, audio_file)\n",
    "\n",
    "                # Check if the audio file (with extension) is in the mapping\n",
    "                if audio_file in mapping:\n",
    "                    try:\n",
    "                        # Load audio file\n",
    "                        y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                        # Extract features\n",
    "                        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=512, n_fft=2048)\n",
    "                        rmse = librosa.feature.rms(y=y)\n",
    "                        delta_mfccs = librosa.feature.delta(mfccs)\n",
    "                        features = np.vstack([mfccs, rmse, delta_mfccs])\n",
    "                        features_processed = np.mean(features.T, axis=0)\n",
    "\n",
    "                        # Append the features and the correct emotion label to the data list\n",
    "                        data.append([features_processed, mapping[audio_file]])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing file {audio_file}: {e}\")\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=['Features', 'Emotion'])\n",
    "\n",
    "# Now df is your dataset ready for further processing and model training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
