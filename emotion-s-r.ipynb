{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = 'C:\\Users\\张佳\\source\\repos\\emotion-speech-recognition\\Emotion Speech Dataset'\n",
    "\n",
    "# Initialize a list to store data\n",
    "data = []\n",
    "\n",
    "# Iterate over each speaker's folder\n",
    "for speaker_folder in os.listdir(base_dir):\n",
    "    speaker_path = os.path.join(base_dir, speaker_folder)\n",
    "\n",
    "    # Read the corresponding text file for the speaker\n",
    "    mapping_file = os.path.join(speaker_path, f\"{speaker_folder}.txt\")\n",
    "    mapping = {}\n",
    "    with open(mapping_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                # Append \".wav\" to the filename from the text file for matching\n",
    "                mapping[parts[0].strip() + \".wav\"] = parts[2].strip()\n",
    "            else:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "\n",
    "    # Process each audio file in the emotion folders\n",
    "    for emotion_folder in os.listdir(speaker_path):\n",
    "        emotion_path = os.path.join(speaker_path, emotion_folder)\n",
    "        if os.path.isdir(emotion_path):\n",
    "            for audio_file in os.listdir(emotion_path):\n",
    "                file_path = os.path.join(emotion_path, audio_file)\n",
    "\n",
    "                # Check if the audio file (with extension) is in the mapping\n",
    "                if audio_file in mapping:\n",
    "                    try:\n",
    "                        # Load audio file\n",
    "                        y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                        # Extract features\n",
    "                        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=512, n_fft=2048)\n",
    "                        rmse = librosa.feature.rms(y=y)\n",
    "                        delta_mfccs = librosa.feature.delta(mfccs)\n",
    "                        features = np.vstack([mfccs, rmse, delta_mfccs])\n",
    "                        features_processed = np.mean(features.T, axis=0)\n",
    "\n",
    "                        # Append the features and the correct emotion label to the data list\n",
    "                        data.append([features_processed, mapping[audio_file]])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing file {audio_file}: {e}\")\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=['Features', 'Emotion'])\n",
    "\n",
    "# Now df is your dataset ready for further processing and model training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
